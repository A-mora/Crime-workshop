---
title: "Understanding perception of the effectiveness of the Criminal Justice System in England and Wales"
author: "Ana Morales"
date: "`r Sys.Date()`"
fontsize: 12pt
output: 
  html_document:
    highlighter: null
    #theme: "yeti"
    theme: "flatly"
    code_download: TRUE
    toc: TRUE
    toc_float: TRUE
    toc_depth: 2
---



In the last session we used exploratory data analysis to make sense and understand the data that we have. This is a fundamental step in any data analysis process, it allow us to know the data, find errors, patterns, etc. It also help us to understand what can and can't do with the data we have. 

We looked at bivariate association between variables, which help us to make us an idea of the relationship between a set of two variables. This is powerful, but rather limited in terms of inference we can make regarding the association between variables. 

It is very unusual, specially in the social sciences, that a response variable will only depend on a single explanatory variable. Usually, we have several variables that affect our outcome variable at the same time, for those case we use multiple linear regression.

In this tutorial we will give you a practical introduction to multiple linear regression. It does not intend to replace a formal theoretical explanation of this data analysis technique, but rather we will only scratch the surface. Hopefully this will also spark some interest (and why not joy?) in you.


We will also discuses the underlying assumption of Multiple linear regression and the interpretation of the results

# Multiple Linear Regression

MLR looks at the **linear** association of between a continuous dependent variable (also known as "outcome") $Y$ and a set of explanatory variables (also known as "predictors") $x_1, x_2, x_3, x_n$. In this tutorial we will explore the association between our dependent variable $Y$ the perception of the effectiveness of the Criminal Justice System and a set of explanatory variables $X_i$ age, whether victim of a crime, sex.

You will normally find a equation similar to this one:

<center>$Y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + \dots + \beta_nx_{in} + \epsilon_i$</center>

We will be back to this equation later.

```{r, message=FALSE}
library(tidyverse)
library(haven)
```

```{r, echo=FALSE}
setwd("C:/Users/Amanda/Desktop/anita/Crime-workshop")

csew <- read_dta("CSEW/UKDA-7911-stata/stata/stata11/csew1314_teaching_eul2.dta")
```


```{r, echo=FALSE}
#attributes(csew$agegrp7)
#table(csew$agegrp7)
csew$agegrp7a<-as_factor(csew$agegrp7)

#table(csew$sexf)
#attributes(csew$bcsvictim)
csew$bcsvictim1<-as_factor(csew$bcsvictim)
csew$sexf<-as_factor(csew$sex)

csew1<- select(csew, effectx, age, bcsvictim1, sexf, nation, ethgrp5a, IndivWgtx)

m0<- lm(effectx ~ age, data = csew1)
m0

m1<- lm(effectx ~ age + bcsvictim1 + sexf + nation+ ethgrp5a, data = csew1, weights = IndivWgtx)
summary(m1)




```

**An important note**

The variable `effectx` effectiveness of the Criminal Justice System is a derived variables made available for teaching purpose only (for more information check the [user guide](http://doc.ukdataservice.ac.uk/doc/7911/mrdoc/pdf/7911_csew_2013-14_teaching_dataset_user_guide.pdf)). In consequences, the conclusion reached from these analysis can not be taken as the real association between the variables analysed.

## Multiple linear regression in R

We use the function `lm` which stand for "linear model" from the R base. The model is specified as follow:

** Simple linear regression**


A simple linear regression is a linear model with 1 outcome and a single explanatory variable

```{r}
m0<- lm(effectx ~ age, data = csew)
summary(m0)
```

There is a lot of information on that output, and we will be checking them all, but step by step. Remember that regression equation above?. This is a version of the same one for a simple linear regression

<center>$Y_i = \beta_0 + \beta_1x_{i1} +  \epsilon_i$ </center>


- $Y_i$: is effectx, our outcome variable
- $x_{i1}$: is age, our explanatory variable
- $\beta_0$: is the intercept term (also known as "slope")
- $\beta_1$: is the estimate value for the variable age

We can assess whether there are significant association between the variables effectx and age by looking at the p-value column (`Pr(>|t|)`), the asterisks  denote how significant they are, `***` is equivalent to 0.001.

**Interpretation**

The association between effectx and age is positive, the value 0.0086867. This is the predicted value of the perception of effectiveness of the CJS score *when age is 1* (remember that we only have data for respondents aged 16 years and older).


This indicate that for each year of age the perception of the effectiveness in the CJS increase by 0.009. This might not seem a lot, but we have to consider the scale of the effectx variable (range from -3 to 2.2 approx.). 

So, the predicted value for a 16 year old will be (using the equation). We will ignore the residual term for now.

$Y_i = \beta_0 + \beta_1x_{i1}
y = -0.44 + 0.009*16
y = -0.296

If you are not a fan of doing calculations by hands, you can use the function predict, we put the data, and the variable in the data that we want to predict, in this case age, followed by the value.

```{r}
predict(m0, data.frame(age = c(16)))
```


Our model is not a very good one, the adjusted R-squared is 0.02438, which means that we are explaining only a 2.4% of the variation of effectx with a single explanatory variable.

## Multiple linear regression

In R this is really simple,  we used the same function as per simple linear regression (SLR), to include more predictors we use the mathematical sign `+`

```{r, eval=FALSE}
m1<- lm(effectx ~ age + bcsvictim1, data = csew)
summary(m1)
```

```{r}
library(car)
residualPlots(m1)
```

The interpretation is similar to the SLR, the only difference here is the inclusion of a categorical variable "bcsvictimf". This variable have only two values, "yes" and "not" but the model will only print one which is called "reference category", here we can see that the reference category is "victim of crime". This will tell you how much or less (depending on the sign) being a victim a crime affect the perception of the effectiveness of the CJS. 


Now is your turn to interpret m1:

**Q1:** How Does being a victim of crime in the previous 12 months associated with the perception of effectiveness of the Criminal Justice Service?
_________________________________________________________________________________
_________________________________________________________________________________

**Q2:** Is this association significant?_________________________________________
_________________________________________________________________________________

**Q3:** Did the model improved after controlling for another variable?________________________________________________________________________


**Your turn**

Now add other predictors to the model and describe your results



# Residuals

Residuals are the differences between the observed values of Y for each case in our data minus the predicted or expected value of Y, the one we obtained with our model. If the model is good, this differences will be minimal and we can say that "our model fits the data well". Unfortunately, most of the time, this is not the case.

Residuals can tell us how much variation is left unexplained after we controlled for key variables. In other words, how much of the variation of the perception of the effectiveness is left unexplained by our model. Remember R-squared is a measure of how much variation we explain, our models don't perform really well here.

We need to find a model that fit the data "adequately", remember the says [**"all models are wrong, but some are useful"**](https://en.wikipedia.org/wiki/George_E._P._Box) (George Box). How do we know if our model is good enough for our research question? besides our literature review, we need to check the assumptions of the model.

# Assumption checkings

##Normality of the residuals

## Predicted versus fitted

```{r}
par(mfrow=c(2,2)) # a function to combine multiple plots into one overall graph

plot(m0) # residual plots
```





